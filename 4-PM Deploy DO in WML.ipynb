{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Deploying a Decision Optimization model with Watson Machine Learning\n\nThis notebook shows you how to deploy a Decision Optimization model, create and monitor jobs, and get solutions using the Watson Machine Learning Python Client.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Set up the Watson Machine Learning client\n\nBefore you use the sample code in this notebook, you need to:\n\n    create a Watson Machine Learning (WML) Service instance. A free plan is offered and information about how to create the instance can be found here.\n\nInstall and then import the Watson Machine Learning client library. This notebook uses the preview Python client based on v4 of Watson Machine Learning APIs.\n\nImportant Do not load both Python client libraries into a notebook.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\u001b[33mWARNING: Skipping watson-machine-learning-client as it is not installed.\u001b[0m\r\n"
                }
            ],
            "source": "# Uninstall the Watson Machine Learning client Python client based on v3 APIs\n\n!pip uninstall watson-machine-learning-client -y"
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: watson-machine-learning-client-V4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.0.54)\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2.21.0)\nRequirement already satisfied: lomond in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.3.3)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2.4.3)\nRequirement already satisfied: pandas in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.24.1)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (4.31.1)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.8.2)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (1.24.1)\nRequirement already satisfied: certifi in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2019.9.11)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client-V4) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client-V4) (3.0.4)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lomond->watson-machine-learning-client-V4) (1.12.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.*,>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client-V4) (2.4.3)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client-V4) (2.4.3)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client-V4) (2018.9)\nRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client-V4) (2.7.5)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client-V4) (1.15.4)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client-V4) (0.9.3)\nRequirement already satisfied: docutils>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client-V4) (0.14)\n"
                }
            ],
            "source": "# Install the WML client API\n\n!pip install watson-machine-learning-client-V4"
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create a client instance\n\nUse your Watson Machine Learning credentials."
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "mkdir: cannot create directory \u2018model\u2019: File exists\r\n"
                }
            ],
            "source": "%mkdir model"
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Overwriting model/main.py\n"
                }
            ],
            "source": "%%writefile model/main.py\n\nfrom docplex.util.environment import get_environment\nfrom os.path import splitext\nimport pandas\nfrom six import iteritems\n\ndef get_all_inputs():\n    '''Utility method to read a list of files and return a tuple with all\n    read data frames.\n    Returns:\n        a map { datasetname: data frame }\n    '''\n    result = {}\n    env = get_environment()\n    for iname in [f for f in os.listdir('.') if splitext(f)[1] == '.csv']:\n        with env.get_input_stream(iname) as in_stream:\n            df = pandas.read_csv(in_stream)\n            datasetname, _ = splitext(iname)\n            result[datasetname] = df\n    return result\n\ndef write_all_outputs(outputs):\n    '''Write all dataframes in ``outputs`` as .csv.\n\n    Args:\n        outputs: The map of outputs 'outputname' -> 'output df'\n    '''\n    for (name, df) in iteritems(outputs):\n        csv_file = '%s.csv' % name\n        print(csv_file)\n        with get_environment().get_output_stream(csv_file) as fp:\n            if sys.version_info[0] < 3:\n                fp.write(df.to_csv(index=False, encoding='utf8'))\n            else:\n                fp.write(df.to_csv(index=False).encode(encoding='utf8'))\n    if len(outputs) == 0:\n        print(\"Warning: no outputs written\")\n        "
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Appending to model/main.py\n"
                }
            ],
            "source": "%%writefile -a model/main.py\n\n#dd-cell\nimport pandas as pd\nimport numpy as np\n\n# Load CSV files into inputs dictionnary\ninputs = get_all_inputs()\ndf_day = inputs['day']\n\ndf_machine = inputs['machine']\n\ndf_predicted_failure = inputs['predicted_failure']\ndf_predicted_failure = df_predicted_failure.set_index(['machine', 'day'])\n\ndf_planned_production = inputs['planned_production']\ndf_planned_production = df_planned_production.set_index(['machine', 'day'])\n\ndf_fixed_maintenance = inputs['fixed_maintenance']\ndf_fixed_maintenance = df_fixed_maintenance.set_index(['machine', 'day'])\n\ndf_parameters = inputs['parameters']\n\n# first global collections to iterate upon\nall_machines = df_machine['id'].values\n\nall_days = df_day['id'].values\n\ndata_cumul_failure = []\nfor machine in all_machines:\n    for i, d in np.ndenumerate(all_days):\n        cumul = 0\n        for i2, d2 in np.ndenumerate(all_days):\n            if i2==i:\n                break\n            cumul += int(df_predicted_failure.failure[machine, d2])\n        data_cumul_failure.append((machine, d, cumul))\n\ndf_cumul_failure = pd.DataFrame(data_cumul_failure, columns=['machine', 'day', 'cumul_failure'])\ndf_cumul_failure=df_cumul_failure.set_index(['machine', 'day'])\n#dd-cell\nfrom docplex.mp.environment import Environment\nenv = Environment()\nenv.print_information()    \n#dd-cell\nfrom docplex.mp.model import Model\nmdl = Model(name=\"PredictiveMaintenance\")\n#dd-cell\n\n# the variables.\nproduction = mdl.continuous_var_matrix(keys1=all_machines, keys2=all_days, name=lambda ns: \"Production_%s_%s\" % (ns[0],ns[1]))\ndf_production = pd.DataFrame({'production': production})\ndf_production.index.names=['all_machines', 'all_days']\n\nmaintenance = mdl.binary_var_matrix(keys1=all_machines, keys2=all_days, name=lambda ns: \"Maintenance_%s_%s\" % (ns[0],ns[1]))\ndf_maintenance = pd.DataFrame({'maintenance': maintenance})\ndf_maintenance.index.names=['all_machines', 'all_days']\n#dd-cell\n# take into account fixed maintenance events\nfixm = int(df_parameters[df_parameters.id=='fix_maintenance']['value'])\nif fixm == 1:\n    for machine in all_machines:\n        for day in all_days:\n            if (df_fixed_maintenance.maintenance[machine, day] == 1):\n                mdl.add_constraint(maintenance[machine, day] == 1)\n#dd-cell\nfor machine in all_machines:       \n    maintenance_loss = int(df_machine[df_machine.id==machine]['maintenance loss'])/100.\n    capacity = int(df_machine[df_machine.id==machine]['capacity'])\n    for day in all_days:   \n        prod = df_planned_production.production[machine, day]\n        #mdl.add_if_then( maintenance[machine, day] == 1, production[machine, day]== 0 )\n        #mdl.add_if_then( maintenance[machine, day] == 0, production[machine, day]== df_production[df_production.machine==machine][df_production.day==day] )\n        if (prod <= capacity*(1-maintenance_loss)):\n            mdl.add_constraint( production[machine, day] == prod )\n        else:\n            mdl.add_constraint( production[machine, day] == prod - (prod-capacity*(1-maintenance_loss))*maintenance[machine, day])\n        \n#dd-cell\n# One maintenance per machine\nfor machine in all_machines:       \n    mdl.add_constraint( mdl.sum(maintenance[machine, day] for day in all_days) == 1)\n    \nmaintenance_crew_size = int(df_parameters[df_parameters.id=='maintenance crew size']['value'])\n\n# One maintenance at a time\nfor day in all_days:       \n    mdl.add_constraint( mdl.sum(maintenance[machine, day] for machine in all_machines) <= maintenance_crew_size)\n\ndata_cost_maintenance = []\ndata_cost_maintenance_detail = []\ncost_kpis = []\n# Cost of repair\n\nfor machine in all_machines:           \n    #print machine\n    life = int(df_machine[df_machine.id==machine]['remaining life'])\n    capacity = int(df_machine[df_machine.id==machine]['capacity'])\n    cost_of_maintenance = int(df_machine[df_machine.id==machine]['cost of maintenance'])\n    maintenance_loss = int(df_machine[df_machine.id==machine]['maintenance loss'])/100.\n    cost_of_repair = int(df_machine[df_machine.id==machine]['cost of repair'])\n    repair_loss = int(df_machine[df_machine.id==machine]['repair loss'])/100.\n    loss_per_life_day = int(df_machine[df_machine.id==machine]['loss per life day'])\n    production_value_unit = int(df_machine[df_machine.id==machine]['production value unit'])\n    \n    previous_day = None\n    for i, day in np.ndenumerate(all_days):\n        cost = 0;\n        prob_break_before = 0\n        fail_prod_cost = 0\n        repair_cost = 0\n        maint_cost = 0\n        prod_cost = 0\n        early_maint_cost = 0\n        \n        if (previous_day != None):\n            prob_break_before = int(df_cumul_failure.cumul_failure[machine, previous_day])/100.\n        previous_day = day\n        \n        #print prob_break_before\n        \n        # Cost of lost production if failure before maintenance\n        for i2, day2 in np.ndenumerate(all_days):\n            if (i2==i):\n                break\n            prob_break_day2 = int(df_predicted_failure.failure[machine, day2])/100.\n            production_day2 = int(df_planned_production.production[machine, day2])\n            if (production_day2 > capacity*(1-repair_loss)):\n                temp = production_value_unit*prob_break_day2*(production_day2 - capacity*(1-repair_loss))\n                fail_prod_cost += temp\n                cost += temp\n                \n            \n        # Cost of repair if breaking before maintenance\n        repair_cost = cost_of_repair*prob_break_before\n        cost += repair_cost\n        \n        \n        # Cost of maintenance\n        maint_cost = cost_of_maintenance*(1-prob_break_before)\n        cost += maint_cost\n        \n        # Cost of lost production for maintenance\n        production_day = int(df_planned_production.production[machine, day])\n        if (production_day > capacity*(1-maintenance_loss)):\n            prod_cost = production_value_unit*(production_day - capacity*(1-maintenance_loss))\n            cost += prod_cost\n            \n        \n        # Cost of maintenance too early\n        early_maint_cost = loss_per_life_day*max(life-i[0], 0)\n        cost += early_maint_cost\n        \n        #print cost\n        data_cost_maintenance.append((machine, day, cost))\n        data_cost_maintenance_detail.append((machine, day, fail_prod_cost, repair_cost, maint_cost, prod_cost, early_maint_cost))\n        \n        cost_kpis.append(cost*maintenance[machine, day])\n        \ncost_kpi = mdl.sum(cost_kpis)\nmdl.add_kpi(cost_kpi, \"Cost\")\n\ndf_cost_maintenance = pd.DataFrame(data_cost_maintenance, columns=['machine', 'day', 'cost_maintenance'])\ndf_cost_maintenance_detail = pd.DataFrame(data_cost_maintenance_detail, columns=['machine', 'day', 'fail_prod_cost', 'repair_cost', 'maint_cost', 'prod_cost', 'early_maint_cost'])\n#print df_cost_maintenance\n#dd-cell\ntotal_planned_production = mdl.sum(df_planned_production.production)\nmdl.add_kpi(total_planned_production, \"Total Planned Production\")\ntotal_production = mdl.sum(df_production.production)\nmdl.add_kpi(total_production, \"Total Production\")\n#dd-cell\nstrategy = int(df_parameters[df_parameters.id=='strategy']['value'])\n\nif (strategy == 1):\n    mdl.minimize(cost_kpi)\nelse:\n    early = 10\n    late = 1000\n    temp = []     \n    for machine in all_machines:           \n        \n        last_day = None\n        for i, day in np.ndenumerate(all_days):\n            last_day = day;\n            cumul_failure = int(df_cumul_failure.cumul_failure[machine, day])\n            if (cumul_failure > 0):                            \n                temp.append(late * maintenance[machine, day] )\n            else:\n                temp.append(early * i[0] * maintenance[machine, day] )\n        \n    late_kpi = mdl.sum(temp)\n    mdl.minimize(late_kpi)\n#dd-cell\ns = mdl.solve(log_output=True)\nassert s, \"solve failed\"\nmdl.report()\n\nall_kpis = [(kp.name, kp.compute()) for kp in mdl.iter_kpis()]\ndf_kpis = pd.DataFrame(all_kpis, columns=['kpi', 'value'])\n    \n#dd-cell\ndf_production = df_production.production.apply(lambda v: v.solution_value)\n#df_production\n#dd-cell\ndf_maintenance = df_maintenance.maintenance.apply(lambda v: v.solution_value)\n#df_maintenance\n#dd-cell\ndf_production = df_production.to_frame()\ndf_production['machine'] = df_production.index.get_level_values('all_machines') \ndf_production['day'] = df_production.index.get_level_values('all_days') \ndf_production.columns = ['production', 'machine', 'day'] \n\n# track production shortage = gap between planned production and actual\nprod_shortage = []\nfor m in all_machines:\n   for d in all_days:\n      prod_shortage.append((m,d,df_planned_production.production[m,d]-df_production.production[m,d]))\n\ndf_production_shortage = pd.DataFrame(prod_shortage, columns=['machine', 'day', 'production_shortage'])\n# end track production shortage\n\ndf_production = df_production.reset_index(drop=True)\n\ndf_maintenance = df_maintenance.to_frame()\ndf_maintenance['machine'] = df_maintenance.index.get_level_values('all_machines') \ndf_maintenance['day'] = df_maintenance.index.get_level_values('all_days') \ndf_maintenance.columns = ['maintenance', 'machine', 'day'] \n\n#track resource load (number of machines maintained each day)\nres_load = []\nfor d in all_days:\n    load = 0\n    for m in all_machines:\n        load += int(df_maintenance.maintenance[m,d])\n    res_load.append((d,load))\ndf_resource_load = pd.DataFrame(res_load, columns=['day', 'load'])\n# end track resource load \n\ndf_cumul_failure['machine'] = df_cumul_failure.index.get_level_values('machine')\ndf_cumul_failure['day'] = df_cumul_failure.index.get_level_values('day')\ndf_cumul_failure.columns = ['failure', 'machine', 'day']\ndf_cumul_failure = df_cumul_failure.reset_index(drop=True)\n\n# detailed maintenance cost\ndf_cost_maintenance_detail['filter'] = df_cost_maintenance_detail.apply(lambda x: df_maintenance.maintenance[x['machine'],x['day']]==1, axis=1)\ndf_cost_maintenance_detail = df_cost_maintenance_detail[df_cost_maintenance_detail['filter'] == True]\ndf_cost_maintenance_detail.drop(['filter'], axis=1, inplace=True)\n\ndf_maintenance = df_maintenance.reset_index(drop=True)\n\n# maintenance kpi: cost breakdown\ndf_cost_maint_sum = df_cost_maintenance_detail.drop(['machine', 'day'], axis=1)\ncost_maint_vals = df_cost_maint_sum.sum().reset_index().values\ndf_maint_kpis = pd.DataFrame(cost_maint_vals, columns=['kpi', 'value'])\n\noutputs = {}\n    \noutputs['cost_maintenance'] = df_cost_maintenance\noutputs['cumul_failure'] = df_cumul_failure\noutputs[\"kpis\"] = df_kpis\noutputs[\"maint_kpis\"] = df_maint_kpis\noutputs[\"maintenance\"] = df_maintenance\noutputs[\"production\"] = df_production\noutputs[\"production_shortage\"] = df_production_shortage\noutputs[\"resource_load\"] = df_resource_load\noutputs['maintenance_cost_detail'] = df_cost_maintenance_detail\n"
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": "import tarfile\ndef reset(tarinfo):\n    tarinfo.uid = tarinfo.gid = 0\n    tarinfo.uname = tarinfo.gname = \"root\"\n    return tarinfo\ntar = tarfile.open(\"model.tar.gz\", \"w:gz\")\ntar.add(\"model/main.py\", arcname=\"main.py\", filter=reset)\ntar.close()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Upload your model on Watson Machine Learning\n\nStore model in Watson Machine Learning with:\n\n    the tar archive previously created,\n    metadata including the model type and runtime\n\nGet the model_uid.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "15db426b-8dee-41d7-9b1f-1717efff0e0c\n"
                }
            ],
            "source": "mnist_metadata = {\n    client.repository.ModelMetaNames.NAME: \"PM Opti\",\n    client.repository.ModelMetaNames.DESCRIPTION: \"Preventive Maintenance Opti Model\",\n    client.repository.ModelMetaNames.TYPE: \"do-docplex_12.9\",\n    client.repository.ModelMetaNames.RUNTIME_UID: \"do_12.9\"    \n}\n\nmodel_details = client.repository.store_model(model='/home/dsxuser/work/model.tar.gz', meta_props=mnist_metadata)\n\nmodel_uid = client.repository.get_model_uid(model_details)\n\nprint( model_uid )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Create a deployment\n\nCreate a batch deployment for the model, providing information such as:\n\n    the maximum number of compute nodes\n    the T-shirt size of the compute nodes\n\nGet the deployment_uid."
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '15db426b-8dee-41d7-9b1f-1717efff0e0c' started\n\n#######################################################################################\n\n\nready.\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='8baf07ca-bb9a-4006-b5ed-0c901b0bb3a1'\n------------------------------------------------------------------------------------------------\n\n\n8baf07ca-bb9a-4006-b5ed-0c901b0bb3a1\n"
                }
            ],
            "source": "meta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: \"PM Deployment\",\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"PM DO Deployment\",\n    client.deployments.ConfigurationMetaNames.BATCH: {},\n    client.deployments.ConfigurationMetaNames.COMPUTE: {'name': 'S', 'nodes': 1}\n}\n\ndeployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n\ndeployment_uid = client.deployments.get_uid(deployment_details)\n\nprint( deployment_uid )"
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "------------------------------------  ---------------------------------------------------  -----  ------------------------  -------------\nGUID                                  NAME                                                 STATE  CREATED                   ARTIFACT_TYPE\n8baf07ca-bb9a-4006-b5ed-0c901b0bb3a1  PM Deployment                                        ready  2019-11-07T23:33:07.181Z  model\n7640fe91-9263-4da1-b05e-4a5fd8ddfcf4  PM Deployment                                        ready  2019-11-07T22:57:57.490Z  model\n9e4a67d8-1468-49fc-b068-569c01e6b74c  Predictive Maintenance Model Py36 Online Deployment  ready  2019-11-07T20:05:41.170Z  model\n7ceaa300-9cb4-4307-a64b-f01bd00fae59  Auto generated DO docplex deployment                 ready  2019-10-25T14:53:04.628Z  model\n6b488d5b-e2c6-4ffa-9cda-e64c931bb195  api2                                                 ready  2019-02-15T00:25:31.594Z  model\nfe6ec487-0ca0-4058-9de7-39ce21f173c2  im an api                                            ready  2019-02-14T22:41:30.317Z  model\nbe71378d-1e7a-48c6-835f-f0885579d249  deployed api                                         ready  2019-02-14T19:21:35.598Z  model\n9ceb4fff-fa56-4547-b2ab-16227dfe1eb2  demo6                                                ready  2019-02-14T01:14:17.667Z  model\n23ef4fdf-db64-41ff-b539-58bf0a8449b1  build me                                             ready  2019-02-13T18:22:42.725Z  model\nc2bfa153-a9eb-4833-a28f-7ab7d5f8ca88  drug deploy                                          ready  2019-02-13T18:01:52.219Z  model\n7bcf3f25-5f6d-4b25-ae58-886e40254e77  web app 1                                            ready  2019-02-09T20:03:23.693Z  model\n84aeb0e6-e44a-4d9b-9b88-af4daf1e0e1f  building code web app                                ready  2018-12-04T12:18:52.540Z  model\nbdb16c46-7e87-42a6-952f-b351d7153d18  Fraud model - auto-generated                         ready  2018-11-06T13:48:49.869Z  model\n------------------------------------  ---------------------------------------------------  -----  ------------------------  -------------\n"
                }
            ],
            "source": "# List all existing deployments\n\nclient.deployments.list()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Create and monitor a job with inline data for your deployed model\u00b6\n\nCreate a payload containing inline input data.\n\nCreate a new job with this payload and the deployment.\n\nGet the job_uid"
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [],
            "source": "solve_payload = {\n    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA_REFERENCES: [\n                  {\n                    \"id\":\"day.csv\",\n                    \"type\": \"s3\",\n                    \"connection\": {\n                        \"endpoint_url\": \"s3-api.us-geo.objectstorage.service.networklayer.com\",\n                        \"access_key_id\": \"2ed76c071b6448ff9f603f30b3431b8a\",\n                        \"secret_access_key\": \"4102030211f936020bf8de5391bfe21e2ca36d23265a6ba3\"\n                    },\n                    \"location\": {\n                        \"bucket\": \"predictivemaintenance-donotdelete-pr-mlejlc5nq1ttru\",\n                        \"path\": \"day.csv\"\n                    }\n                },\n                {\n                    \"id\":\"machine.csv\",\n                    \"type\": \"s3\",\n                    \"connection\": {\n                        \"endpoint_url\": \"s3-api.us-geo.objectstorage.service.networklayer.com\",\n                        \"access_key_id\": \"2ed76c071b6448ff9f603f30b3431b8a\",\n                        \"secret_access_key\": \"4102030211f936020bf8de5391bfe21e2ca36d23265a6ba3\"\n                    },\n                    \"location\": {\n                        \"bucket\": \"predictivemaintenance-donotdelete-pr-mlejlc5nq1ttru\",\n                        \"path\": \"machine.csv\"\n                    }\n                },\n                {\n                    \"id\":\"predicted_failure.csv\",\n                    \"type\": \"s3\",\n                    \"connection\": {\n                        \"endpoint_url\": \"s3-api.us-geo.objectstorage.service.networklayer.com\",\n                        \"access_key_id\": \"2ed76c071b6448ff9f603f30b3431b8a\",\n                        \"secret_access_key\": \"4102030211f936020bf8de5391bfe21e2ca36d23265a6ba3\"\n                    },\n                    \"location\": {\n                        \"bucket\": \"predictivemaintenance-donotdelete-pr-mlejlc5nq1ttru\",\n                        \"path\": \"predicted_failure.csv\"\n                    }\n                },\n                {\n                    \"id\":\"planned_production.csv\",\n                    \"type\": \"s3\",\n                    \"connection\": {\n                        \"endpoint_url\": \"s3-api.us-geo.objectstorage.service.networklayer.com\",\n                        \"access_key_id\": \"2ed76c071b6448ff9f603f30b3431b8a\",\n                        \"secret_access_key\": \"4102030211f936020bf8de5391bfe21e2ca36d23265a6ba3\"\n                    },\n                    \"location\": {\n                        \"bucket\": \"predictivemaintenance-donotdelete-pr-mlejlc5nq1ttru\",\n                        \"path\": \"planned_production.csv\"\n                    }\n                },\n                {\n                    \"id\":\"parameters.csv\",\n                    \"type\": \"s3\",\n                    \"connection\": {\n                        \"endpoint_url\": \"s3-api.us-geo.objectstorage.service.networklayer.com\",\n                        \"access_key_id\": \"2ed76c071b6448ff9f603f30b3431b8a\",\n                        \"secret_access_key\": \"4102030211f936020bf8de5391bfe21e2ca36d23265a6ba3\"\n                    },\n                    \"location\": {\n                        \"bucket\": \"predictivemaintenance-donotdelete-pr-mlejlc5nq1ttru\",\n                        \"path\": \"parameters.csv\"\n                    }\n                },\n                {\n                    \"id\":\"fixed_maintenance.csv\",\n                    \"type\": \"s3\",\n                    \"connection\": {\n                        \"endpoint_url\": \"s3-api.us-geo.objectstorage.service.networklayer.com\",\n                        \"access_key_id\": \"2ed76c071b6448ff9f603f30b3431b8a\",\n                        \"secret_access_key\": \"4102030211f936020bf8de5391bfe21e2ca36d23265a6ba3\"\n                    },\n                    \"location\": {\n                        \"bucket\": \"predictivemaintenance-donotdelete-pr-mlejlc5nq1ttru\",\n                        \"path\": \"fixed_maintenance.csv\"\n                    }\n                }\n            ],\n        client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n            {\n                \"id\":\".*\\\\.csv\"\n            }\n       ]\n    }"
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "84e4b2a7-72c5-4bd4-90ef-ec146974f42a\n"
                }
            ],
            "source": "job_details = client.deployments.create_job(deployment_uid, solve_payload)\njob_uid = client.deployments.get_job_uid(job_details)\n\nprint( job_uid )"
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "queued...\nqueued...\nqueued...\nqueued...\nqueued...\nrunning...\nrunning...\ncompleted\n"
                }
            ],
            "source": "from time import sleep\n\nwhile job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n    sleep(5)\n    job_details=client.deployments.get_job_details(job_uid)\n\nprint( job_details['entity']['decision_optimization']['status']['state'])"
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'state': 'completed', 'running_at': '2019-11-07T23:33:44.168Z', 'completed_at': '2019-11-07T23:33:47.149Z'}\n"
                }
            ],
            "source": "print( job_details['entity']['decision_optimization']['status'])"
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'SUCCESS'"
                    },
                    "execution_count": 65,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "client.deployments.delete(deployment_uid)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}