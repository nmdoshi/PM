{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "#dd-ignore\n\n!pip install --user dd-scenario\n"
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "#dd-ignore\n\nfrom dd_scenario import *\n\n# Creates a client...\n# If you want to be able to call solve() on the client, you have to provide your API Key\n# client = Client(pc=pc, apikey='IAM_APIKEY')\nclient = Client(pc=pc)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "#dd-ignore\n\n#Get 'PMDO' decision...\ndd_model_builder = client.get_model_builder(name=\"PMDO\")\n\n#Get scenario 'Optimized MA'...\nscenario = dd_model_builder.get_scenario(name=\"Optimized MA\")\n\n#Load all input data as a map { data_name: data_frame }\ninputs = scenario.get_tables_data(category='input')\n# This will hold all outputs as a map { data_name: data_frame }\noutputs = {}\n\n# we use a lock to access ``outputs``. This allows solves() to\n# be aborted without race condition in data writting\nimport threading\noutput_lock = threading.Lock()\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "from docplex.mp.model import *\nfrom docplex.mp.utils import *\nfrom docplex.util.status import JobSolveStatus\nfrom docplex.mp.conflict_refiner import ConflictRefiner, VarUbConstraintWrapper, VarLbConstraintWrapper\nfrom docplex.mp.relaxer import Relaxer\nimport time\nimport sys\nimport operator\n\nimport pandas as pd\nimport numpy as np\nimport math\n\nimport codecs\nimport sys\n\n# Handle output of unicode strings\nif sys.version_info[0] < 3:\n    sys.stdout = codecs.getwriter('utf8')(sys.stdout)\n\n\n# Label constraint\ndef helper_add_labeled_cplex_constraint(mdl, expr, label, context=None, columns=None):\n    global expr_counter\n    if isinstance(expr, np.bool_):\n        expr = expr.item()\n    if isinstance(expr, bool):\n        pass  # Adding a trivial constraint: if infeasible, docplex will raise an exception it is added to the model\n    else:\n        expr.name = '_L_EXPR_' + str(len(expr_to_info) + 1)\n        if columns:\n            ctxt = \", \".join(str(getattr(context, col)) for col in columns)\n        else:\n            if context:\n                ctxt = context.Index if isinstance(context.Index, str) is not None else \", \".join(context.Index)\n            else:\n                ctxt = None\n        expr_to_info[expr.name] = (label, ctxt)\n    mdl.add(expr)\n\ndef helper_get_column_name_for_property(property):\n    return helper_property_id_to_column_names_map.get(property, 'unknown')\n\n\ndef helper_get_index_names_for_type(dataframe, type):\n    if not is_pandas_dataframe(dataframe):\n        return None\n    return [name for name in dataframe.index.names if name in helper_concept_id_to_index_names_map.get(type, [])]\n\n\nhelper_concept_id_to_index_names_map = {\n    'machine': ['id_of_Machine'],\n    'cAssignmentValueConcept': ['id_of_Predicted_failure'],\n    'cResource': ['id_of_Day'],\n    'day': ['id_of_Day'],\n    'cActivity': ['id_of_Machine'],\n    'predicted_failure': ['id_of_Predicted_failure']}\nhelper_property_id_to_column_names_map = {\n    'cAssignmentValueConcept.value': 'failure',\n    'predicted_failure.machine': 'machine',\n    'predicted_failure.day': 'day',\n    'cAssignmentValueConcept.resource': 'day',\n    'machine.id': 'id',\n    'predicted_failure.failure': 'failure',\n    'cAssignmentValueConcept.activity': 'machine',\n    'day.id': 'id'}\n\n\n# Data model definition for each table\n# Data collection: list_of_Day ['id']\n# Data collection: list_of_Machine ['id']\n# Data collection: list_of_Predicted_failure ['day', 'failure', 'machine', '__line']\n\n# Create a pandas Dataframe for each data table\nlist_of_Day = inputs[u'day']\nlist_of_Day = list_of_Day[[u'id']].copy()\nlist_of_Day.rename(columns={u'id': 'id'}, inplace=True)\nlist_of_Machine = inputs[u'machine']\nlist_of_Machine = list_of_Machine[[u'id']].copy()\nlist_of_Machine.rename(columns={u'id': 'id'}, inplace=True)\nlist_of_Predicted_failure = inputs[u'predicted_failure']\nlist_of_Predicted_failure = list_of_Predicted_failure[[u'day', u'failure', u'machine']].copy()\nlist_of_Predicted_failure.rename(columns={u'day': 'day', u'failure': 'failure', u'machine': 'machine'}, inplace=True)\n\n# Set index when a primary key is defined\nlist_of_Day.set_index('id', inplace=True)\nlist_of_Day.sort_index(inplace=True)\nlist_of_Day.index.name = 'id_of_Day'\nlist_of_Machine.set_index('id', inplace=True)\nlist_of_Machine.sort_index(inplace=True)\nlist_of_Machine.index.name = 'id_of_Machine'\nlist_of_Predicted_failure.index.name = 'id_of_Predicted_failure'\n\n\n# Create data frame as cartesian product of: Day x Machine\nlist_of_ResourceAssignment = pd.DataFrame(index=pd.MultiIndex.from_product((list_of_Day.index, list_of_Machine.index), names=['id_of_Day', 'id_of_Machine']))\n\n\n\n\ndef build_model():\n    mdl = Model()\n\n    # Definition of model variables\n    list_of_ResourceAssignment['resourceAssignmentVar'] = mdl.binary_var_list(len(list_of_ResourceAssignment))\n\n\n    # Definition of model\n    # Objective cMaximizeAssignmentsAutoSelected-\n    # Combine weighted criteria: \n    # \tcMaximizeAssignmentsAutoSelected cMaximizeAssignmentsAutoSelected 1.2{\n    # \tcMaximizeAssignments.assignment = cResourceAssignment[day, machine],\n    # \tcScaledGoal.scaleFactorExpr = 1,\n    # \tcSingleCriterionGoal.goalFilter = null,\n    # \tcSingleCriterionGoal.numericExpr = decisionPath(cResourceAssignment[day, machine])} with weight 5.0\n    # \tcMaximizeAssignmentValue cMaximizeAssignmentValue 1.2{\n    # \tcMaximizeAssignmentValue.assignment = cResourceAssignment[day, machine],\n    # \tcMaximizeAssignmentValue.assignmentValue = predicted_failure,\n    # \tcScaledGoal.scaleFactorExpr = 1,\n    # \tcSingleCriterionGoal.goalFilter = null,\n    # \tcSingleCriterionGoal.numericExpr = total predicted_failure [join dimensions(cResourceAssignment[day, machine] / day, cResourceAssignment[day, machine] / machine) with dimensions(predicted_failure / day, predicted_failure / machine)] / failure over cResourceAssignment[day, machine]} with weight 5.0\n    agg_ResourceAssignment_resourceAssignmentVar_SG1 = mdl.sum(list_of_ResourceAssignment.resourceAssignmentVar)\n    join_ResourceAssignment_SG2 = list_of_ResourceAssignment.reset_index().merge(list_of_Predicted_failure.reset_index(), left_on=['id_of_Day', 'id_of_Machine'], right_on=['day', 'machine']).set_index(['id_of_Day', 'id_of_Machine', 'id_of_Predicted_failure'])\n    join_Predicted_failure_SG2 = list_of_Predicted_failure.join(join_ResourceAssignment_SG2, rsuffix='_right', how='inner')\n    reindexed_Predicted_failure_SG2 = join_Predicted_failure_SG2.reset_index().set_index(['id_of_Day', 'id_of_Machine'])\n    join_ResourceAssignment_SG2_2 = list_of_ResourceAssignment.reset_index().merge(reindexed_Predicted_failure_SG2.reset_index(), left_on=['id_of_Day', 'id_of_Machine'], right_on=['id_of_Day', 'id_of_Machine'], suffixes=('', '_right')).set_index(['id_of_Day', 'id_of_Machine'])\n    join_ResourceAssignment_SG2_2['conditioned_failure'] = join_ResourceAssignment_SG2_2.resourceAssignmentVar * join_ResourceAssignment_SG2_2.failure\n    agg_ResourceAssignment_conditioned_failure_SG2 = mdl.sum(join_ResourceAssignment_SG2_2.conditioned_failure)\n    \n    kpis_expression_list = [\n        (1, 16.0, agg_ResourceAssignment_resourceAssignmentVar_SG1, 1, 0, u'the number of day to machine assignments'),\n        (1, 16.0, agg_ResourceAssignment_conditioned_failure_SG2, 1, 0, u'overall quality of day to machine assignments according to predicted_failures')]\n    custom_code.update_goals_list(kpis_expression_list)\n    \n    for _, kpi_weight, kpi_expr, kpi_factor, kpi_offset, kpi_name in kpis_expression_list:\n        mdl.add_kpi(kpi_weight * ((kpi_expr * kpi_factor) - kpi_offset), publish_name=kpi_name)\n    \n    mdl.maximize(sum([kpi_sign * kpi_weight * ((kpi_expr * kpi_factor) - kpi_offset) for kpi_sign, kpi_weight, kpi_expr, kpi_factor, kpi_offset, kpi_name in kpis_expression_list]))\n    \n    # [ST_1] Constraint : cLimitNumberOfResourcesAssignedToEachActivity_cIterativeRelationalConstraint\n    # The number of days assigned to each machine is less than or equal to 1\n    # Label: CT_1_The_number_of_days_assigned_to_each_machine_is_less_than_or_equal_to_1\n    groupbyLevels = ['id_of_Machine']\n    groupby_ResourceAssignment = list_of_ResourceAssignment.resourceAssignmentVar.groupby(level=groupbyLevels).sum().to_frame()\n    for row in groupby_ResourceAssignment.itertuples(index=True):\n        helper_add_labeled_cplex_constraint(mdl, row.resourceAssignmentVar <= 1, u'The number of days assigned to each machine is less than or equal to 1', row)\n    \n    # [ST_2] Constraint : cBasicLimitNumberOfActivitiesAssignedToEachResource_cIterativeRelationalConstraint\n    # The number of machines assigned to each day is less than or equal to 2\n    # Label: CT_2_The_number_of_machines_assigned_to_each_day_is_less_than_or_equal_to_2\n    groupbyLevels = ['id_of_Day']\n    groupby_ResourceAssignment = list_of_ResourceAssignment.resourceAssignmentVar.groupby(level=groupbyLevels).sum().to_frame()\n    for row in groupby_ResourceAssignment.itertuples(index=True):\n        helper_add_labeled_cplex_constraint(mdl, row.resourceAssignmentVar <= 2, u'The number of machines assigned to each day is less than or equal to 2', row)\n\n\n    return mdl\n\n\ndef solve_model(mdl):\n    mdl.parameters.timelimit = 120\n    # Call to custom code to update parameters value\n    custom_code.update_solver_params(mdl.parameters)\n    # Update parameters value according to environment variables definition\n    cplex_param_env_prefix = 'ma.cplex.'\n    cplex_params = [name.qualified_name for name in mdl.parameters.generate_params()]\n    for param in cplex_params:\n        env_param = cplex_param_env_prefix + param\n        param_value = get_environment().get_parameter(env_param)\n        if param_value:\n            # Updating parameter value\n            print(\"Updated value for parameter %s = %s\" % (param, param_value))\n            parameters = mdl.parameters\n            for p in param.split('.')[1:]:\n                parameters = parameters.__getattribute__(p)\n            parameters.set(param_value)\n\n    msol = mdl.solve(log_output=True)\n    if not msol:\n        print(\"!!! Solve of the model fails\")\n        if mdl.get_solve_status() == JobSolveStatus.INFEASIBLE_SOLUTION or mdl.get_solve_status() == JobSolveStatus.INFEASIBLE_OR_UNBOUNDED_SOLUTION:\n            crefiner = ConflictRefiner()\n            conflicts = crefiner.refine_conflict(model, log_output=True)\n            export_conflicts(conflicts)\n            \n    print('Solve status: %s' % mdl.get_solve_status())\n    mdl.report()\n    return msol\n\n\nexpr_to_info = {}\n\n\ndef export_conflicts(conflicts):\n    # Display conflicts in console\n    print('Conflict set:')\n    list_of_conflicts = pd.DataFrame(columns=['constraint', 'context', 'detail'])\n    for conflict, index in zip(conflicts, range(len(conflicts))):\n        st = conflict.status\n        ct = conflict.element\n        label, context = expr_to_info.get(conflict.name, ('N/A', conflict.name))\n        label_type = type(conflict.element)\n        if isinstance(conflict.element, VarLbConstraintWrapper) \\\n                or isinstance(conflict.element, VarUbConstraintWrapper):\n            label = 'Upper/lower bound conflict for variable: {}'.format(conflict.element._var)\n            context = 'Decision variable definition'\n            ct = conflict.element.get_constraint()\n\n        # Print conflict information in console\n        print(\"Conflict involving constraint: %s, \\tfor: %s -> %s\" % (label, context, ct))\n        list_of_conflicts = list_of_conflicts.append({'constraint': label, 'context': str(context), 'detail': ct},\n                                                     ignore_index=True)\n\n    # Update of the ``outputs`` dict must take the 'Lock' to make this action atomic,\n    # in case the job is aborted\n    global output_lock\n    with output_lock:\n        outputs['list_of_conflicts'] = list_of_conflicts\n\n\ndef export_solution(msol):\n    start_time = time.time()\n    list_of_ResourceAssignment_solution = pd.DataFrame(index=list_of_ResourceAssignment.index)\n    list_of_ResourceAssignment_solution['resourceAssignmentVar'] = msol.get_values(list_of_ResourceAssignment.resourceAssignmentVar.values)\n\n    # Filter rows for non-selected assignments\n    list_of_ResourceAssignment_solution = list_of_ResourceAssignment_solution[list_of_ResourceAssignment_solution.resourceAssignmentVar > 0.5]\n\n    # Update of the ``outputs`` dict must take the 'Lock' to make this action atomic,\n    # in case the job is aborted\n    global output_lock\n    with output_lock:\n        outputs['list_of_ResourceAssignment_solution'] = list_of_ResourceAssignment_solution.reset_index()\n        custom_code.post_process_solution(msol, outputs)\n\n    elapsed_time = time.time() - start_time\n    print('solution export done in ' + str(elapsed_time) + ' secs')\n    return\n\n\n# Instantiate CustomCode class if definition exists\ntry:\n    custom_code = CustomCode(globals())\nexcept NameError:\n    # Create a dummy anonymous object for custom_code\n    custom_code = type('', (object,), {'preprocess': (lambda *args: None),\n                                       'update_goals_list': (lambda *args: None),\n                                       'update_model': (lambda *args: None),\n                                       'update_solver_params': (lambda *args: None),\n                                       'post_process_solution': (lambda *args: None)})()\n\n# Custom pre-process\ncustom_code.preprocess()\n\nprint('* building wado model')\nstart_time = time.time()\nmodel = build_model()\n\n# Model customization\ncustom_code.update_model(model)\n\nelapsed_time = time.time() - start_time\nprint('model building done in ' + str(elapsed_time) + ' secs')\n\nprint('* running wado model')\nstart_time = time.time()\nmsol = solve_model(model)\nelapsed_time = time.time() - start_time\nprint('model solve done in ' + str(elapsed_time) + ' secs')\nif msol:\n    export_solution(msol)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}